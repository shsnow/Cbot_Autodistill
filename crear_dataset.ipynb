{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c59d9e5",
   "metadata": {},
   "source": [
    "# Definir variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01fd01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO = \"./videos/casa_de_cambio_2-20250901_mix_hasta_1430.mp4\"\n",
    "FRAMES_DIR = \"./frames\"     # Directorio donde se guardaran los frames extraidos del video\n",
    "DATASET_DIR = \"./dataset\"   # Directorio donde se guardara el dataset generado por autodistill\n",
    "FRAME_RATE = 1              # FPS a los que se extraeran los frames\n",
    "\n",
    "from autodistill.detection import CaptionOntology\n",
    "\n",
    "# Ontología para crear clases -> { \"lo que el modelo buscara\" : \"nombre final de la clase\" }\n",
    "ontology = CaptionOntology({\n",
    "    \"vehicle\": \"vehicle\",\n",
    "    \"person\": \"person\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3284e1ef",
   "metadata": {},
   "source": [
    "# Extraer Frames de Video en Alta calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac30a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "if not INPUT_VIDEO:\n",
    "    raise ValueError(\"Set INPUT_VIDEO to the path of the video file.\")\n",
    "if not FRAMES_DIR:\n",
    "    raise ValueError(\"Set FRAMES_DIR to the output directory for frames.\")\n",
    "if not FRAME_RATE or FRAME_RATE <= 0:\n",
    "    raise ValueError(\"FRAME_RATE must be a positive number.\")\n",
    "if shutil.which(\"ffmpeg\") is None:\n",
    "    raise EnvironmentError(\"ffmpeg is not installed or not in PATH.\")\n",
    "\n",
    "in_path = Path(INPUT_VIDEO)\n",
    "out_dir = Path(FRAMES_DIR) / in_path.stem\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cca956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames extracted to: frames/casa_de_cambio_2-20250901_mix_hasta_1430\n"
     ]
    }
   ],
   "source": [
    "output_pattern = str(out_dir / \"frame_%06d.png\")  # PNG for lossless (max quality)\n",
    "\n",
    "cmd = [\n",
    "    \"ffmpeg\",\n",
    "    \"-hide_banner\",\n",
    "    \"-hwaccel\", \"cuda\",\n",
    "    \"-loglevel\", \"error\",\n",
    "    \"-i\", str(in_path),\n",
    "    \"-vf\", f\"fps={FRAME_RATE}\",\n",
    "    \"-vsync\", \"0\",\n",
    "    \"-y\",\n",
    "    output_pattern,\n",
    "]\n",
    "\n",
    "subprocess.run(cmd, check=True)\n",
    "print(f\"Frames extracted to: {out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef411d39",
   "metadata": {},
   "source": [
    "# Etiquetar usando Grounding DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a758797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# truquito para que no de problemas de CUDA con GPUs RTX 3000\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    raise EnvironmentError(\"CUDA is not available on this machine.\")\n",
    "\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    # use bfloat16 for the entire notebook\n",
    "    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    if torch.cuda.get_device_properties(0).major >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da5f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to load grounding dino directly\n",
      "final text_encoder_type: bert-base-uncased\n",
      "Etiquetando frames en ./frames/casa_de_cambio_2-20250901_mix_hasta_1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling ./frames/casa_de_cambio_2-20250901_mix_hasta_1430/frame_000205.png:   0%|          | 0/262 [00:00<?, ?it/s]The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "None of the inputs have requires_grad=True. Gradients will be None\n",
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "Labeling ./frames/casa_de_cambio_2-20250901_mix_hasta_1430/frame_000190.png: 100%|██████████| 262/262 [01:48<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled dataset created - ready for distillation.\n",
      "Dataset creado en: ./dataset/casa_de_cambio_2-20250901_mix_hasta_1430\n"
     ]
    }
   ],
   "source": [
    "from autodistill_grounding_dino import GroundingDINO\n",
    "\n",
    "base_model = GroundingDINO(ontology=ontology)\n",
    "\n",
    "print(f\"Etiquetando frames en ./frames/{out_dir.name}\")\n",
    "\n",
    "base_model.label(input_folder=f\"./frames/{out_dir.name}\", extension=\".png\", output_folder=f\"./dataset/{out_dir.name}\")\n",
    "\n",
    "print(f\"Dataset creado en: ./dataset/{out_dir.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35b2fd",
   "metadata": {},
   "source": [
    "# Combinar imagenes y etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movidos 262 imágenes y 262 etiquetas\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path(DATASET_DIR) / out_dir.name\n",
    "\n",
    "dst_images = base_dir / \"images\"\n",
    "dst_annotations = base_dir / \"annotations\"\n",
    "dst_images.mkdir(parents=True, exist_ok=True)\n",
    "dst_annotations.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def move_all_files(src_dir: Path, dst_dir: Path, split_tag: str | None, exts=None) -> int:\n",
    "    if not src_dir.is_dir() or src_dir.resolve() == dst_dir.resolve():\n",
    "        return 0\n",
    "    count = 0\n",
    "    for p in src_dir.iterdir():\n",
    "        if not p.is_file() or (exts and p.suffix.lower() not in exts):\n",
    "            continue\n",
    "        target = dst_dir / p.name\n",
    "        if target.exists():\n",
    "            stem, suffix = p.stem, p.suffix\n",
    "            tag = f\"_{split_tag}\" if split_tag else \"\"\n",
    "            i = 0\n",
    "            while True:\n",
    "                suffix_i = \"\" if i == 0 else f\"_{i}\"\n",
    "                candidate = dst_dir / f\"{stem}{tag}{suffix_i}{suffix}\"\n",
    "                if not candidate.exists():\n",
    "                    target = candidate\n",
    "                    break\n",
    "                i += 1\n",
    "        shutil.move(str(p), str(target))\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "img_exts = {\".jpg\", \".jpeg\", \".png\"}\n",
    "label_exts = {\".txt\"}\n",
    "\n",
    "moved_imgs = 0\n",
    "moved_lbls = 0\n",
    "for split in (\"train\", \"valid\"):\n",
    "    moved_imgs += move_all_files(base_dir / split / \"images\", dst_images, split, img_exts)\n",
    "    moved_lbls += move_all_files(base_dir / split / \"labels\", dst_annotations, split, label_exts)\n",
    "\n",
    "print(f\"Movidos {moved_imgs} imágenes y {moved_lbls} etiquetas\")\n",
    "\n",
    "# Remove train and valid directories (since these are empty now)\n",
    "shutil.rmtree(base_dir / \"train\", ignore_errors=True)\n",
    "shutil.rmtree(base_dir / \"valid\", ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbot-autodistill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
